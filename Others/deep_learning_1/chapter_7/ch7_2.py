#합성곱 계층

'''
CNN에서는 패팅padding, 스트라이트stride 등 고유의 용어가 등장한다.
각 계층 사이에는 3차원 데이터같이 입체적인 데이터가 흐른다는 점에서 완전연결 신경망과 다르다.


*완전연결 계층의 문제점

데이터의 형상이 무시된다는 문제가 있다.
입력 데이터가 이미지인 경우, 3차원 데이터를 평평한 1차원 데이터로 평탄화해줘야 하는데,\
완전 연결된 계층은 형상을 무시하고 모든 입력 데이터를 동등한 뉴런(같은 차원의 뉴런)으로 취급한다.

한편, 합성곱 계층은 형상을 유지한다.
이미지도 3차원 데이터로 입력받고, 마찬가지로 다음 계층에도 3차원 데이터로 전달한다.
-> 이미지처럼 형상을 가진 데이터를 제대로 이해할 수 있다.

합성곱 계층의 입출력 데이터-> 특정 맵feature map
합성곱 계층의 입력 데이터-> 입력 특징 맵input feature map
합성곱 계층의 출력 데이터-> 출력 특징 맵output feature map


*합성곱 연산

합성곱 연산은 이미지 처리에서 말하는 필터 연산에 해당한다.
-> 입력 데이터에 필터를 적용한다.
-> 입력 데이터는 세로,가로 방향의 형상을 가졌고, 필터 역시 세로,가로 방향의 차원을 갖는다.

데이터와 필터의 형상을 (높이height, 너비width)로 표기하며, 필터를 커널이라고 칭하기도 한다.
합성곱 연산은 필터의 윈도우window를 일정 간격으로 이동해가며 입력 데이터에 적용한다.
-> 입력과 필터에서 대응하는 원소끼리 곱한 후 그 총합을 구한다.
-> 단일 곱셈 누산fused multiply-add,FMA

편향은 필터를 적용한 후의 데이터에 더해진다.
그리고 편향은 항상 하나(1x1)만 존재한다.


*패딩

합성곱 연산을 수행하기 전에 입력 데이터 주변을 특정 값(예컨대 0)으로 채우기도 한다-> 패딩
패딩은 1, 2, 3,... 원하는 정수로 설정할 수 있다.
패딩은 주로 출력 크기를 조정할 목적으로 사용한다.

예를 들어, (4,4) 입력 데이터에 (3,3) 필터를 적용하면 출력은 (2,2)가 되어 입력보다 2만큼 줄어든다.
이는 합성곱 연산을 몇 번이나 되풀이하는 심층 신경망에서는 문제가 될 수 있다.

합성곱 연산을 거칠 때마다 크기가 작아지면 어느 시점에서는 출력의 크기가 1이 되는데, 이는\
더 이상 합성곱 연산을 적용할 수 없다는 뜻이다.
-> 패딩의 폭을 1로 설정하면 (4,4) 입력에 대한 출력이 같은 크기인 (4,4)로 유지된다.
-> 입력 데이터의 공간적 크기를 고정한 채로 다음 계층에 전달할 수 있다.


*스트라이드

스트라이드를 2로 하면 필터를 적용하는 윈도우가 2 칸씩 이동한다.
스트라이드는 필터를 적용하는 간격을 지정한다.
-> 스트라이드를 키우면 출력의 크기는 작아진다.

입력 크기를 (H,W), 필터 크기를 (FH, FW), 출력 크기를 (OH, OW), 패딩을 P,
스트라이드를 S라 하면

OH={(H+2P-FH)/S}+1  
OW={(W+2P-FW)/s}+1


*padding에 곱해진 2는 출력 값이 정수가 되기 위해 설정된 옵션이다.
출력 값은 정수로 나눠 떨어지는 값이어야 한다.
-> 출력 크기가 정수가 아니라면 오류를 내는 등의 대응을 해줘야 한다.
-> 딥러닝 프레임워크 중에는 값이 딱 나눠 떨어지지 않을 때는 가장 가까운 정수로 반올림을 하는 등\
특별히 에러를 내지 않고 진행하도록 구현하는 경우도 있다.


*3차원 데이터의 합성곱 연산

이미지만 해도 세로, 가로에 더해 채널까지 고려한 3차원 데이터이다.
2차원일 때와 비교하면, 길이 방향(채널 방향)으로 특정 맵이 늘어났다.
채널 쪽으로 특정 맵이 여러 개 있다면 입력 데이터와 필터의 합성곱 연산을 채널마다 수행하고\
그 결과에 더해서 하나의 출력을 얻는다.
-> 주의할 점은 입력 데이터의 채널 수와 필터의 채널 수가 같아야 한다.
-> 필터 자체의 크기는 원하는 값으로 설정할 수 있다(단,모든 채널의 필터가 같은 크기여야 한다.)


*블록으로 생각하기

3차원 합성곱 연산은 데이터와 필터를 직육면체 블록이라고 생각하면 쉽다.
블록은 3차원 직육면체이다.
3차원 데이터를 다차원 배열로 나타낼 때는 (채널channel, 높이height, 너비width) 순서로 쓰겠다.

채널수C, 높이H, 너비W인 데이터의 형상은 (C,H,W)로 쓴다.
필터도 같은 순으로 쓴다.
-> 채널수C, 필터 높이FH(filter height), 필터 너비(filter width)의 경우 (C, FH, FW)로 쓴다.

출력 데이터는 한 장의 특징 맵이다.
한 장의 특징 맵을 다른 말로 하면 채널이 1개인 맵이다.
-> 합성곱 연산의 출력으로 다수의 채널을 내보내려면 필터(가중치)를 다수 사용하는 것이다.

필터를 FN개 적용하면 출력 맵도 FN개 생성된다.
FN개의 맵을 모으면 형상이 (FN, OH, OW)인 블록이 완성된다.
이 완성된 블록을 다음 계층으로 넘기는 것이 CNN의 흐름이다.

합성곱 연산에서는 필터의 수도 고려해야 한다.
필터의 가중치 데이터는 4차원 데이터이며(출력 채널 수, 입력 채널 수, 높이, 너비) 순으로 쓴다.
-> 채널 수3, 크기 5x5인 필터가 20개 있다면 (20, 3, 5, 5)로 쓴다.

합성곱 연산에서도 편향이 쓰인다.
편향은 채널 하나에 값 하나씩으로 구성된다.
형상이 다른 블록의 덧셈은 넘파이의 브로트캐스트 기능으로 쉽게 구현 가능하다.


*배치 처리

신경망에서는 입력 데이터를 한 덩어리로 묶어 배치로 처리했다.
완전 연결 신경망을 구현하면서는 이 방식을 지원하여 처리 효율을 높이고, 미니배치 방식의 학습도\
지원하도록 했다.

합성곱 연산도 마찬가지로 배치 처리를 지원하고자 한다.
각 계층을 흐르는 데이터의 차원을 하나 늘려 4차원 데이터로 저장한다.
구체적으로는 데이터를 (데이터 수, 채널 수, 높이, 너비) 순으로 저장한다.
데이터가 N개일 때 배치 처리한다면 

N개의 데이터                             N개의 데이터                         N개의 데이터

 (N,C,H,W)  *   (FN,C,FH,FW)    ->      (N,FN,OH,OW)    +   (FN,1,1)    ->  (N,FN,OH,OW)

입력 데이터          필터                                       편향           출력 데이터


배치 처리 시의 데이터 흐름을 보면 각 데이터의 선두에 배치용 차원을 추가했다.
이처럼 데이터는 4차원 형상을 가진 채 각 계층을 타고 흐른다.
여기에서 주의할 점은 신경망에 4차원 데이터가 하나 흐를 때마다 데이터 N개에 대한 합성곱 연산이\
이뤄진다는 것이다.
-> N회 분의 처리를 한 번에 수행한다.
'''