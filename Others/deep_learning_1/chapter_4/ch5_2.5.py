#왜 손실 함수를 설정하는가?
'''
손실 함수를 사용하는 목적은 높은 '정확도'를 끌어내는 매개변수 값을 찾는 것이다.

신경망 학습에서는 최적의 매개변수(가중치와 편향)를 탐색할 때 손실 함수의 값을 가능한 한\
작게 하는 매개변수를 찾는다.
이때 매개변수의 미분(정확히는 기울기)을 계산하고, 그 미분 값을 단서로 매개변수의 값을\
서서히 갱신하는 과정을 반복한다.

가령 가상의 신경망이 있고 그 신경망의 어느 한 가중치 매개변수에 주목한다고 하자.
이때 그 가중치 매개변수의 손실 함수의 미분이란 '가중치 매개변수의 값을 아주 조금 변화시킬 때\
어떻게 변화하는가'를 의미한다.
반대로, 미분 값이 양(+)일때 가중치 매개변수를 음의 방향으로 변화시켜 손실 함수의 값을 줄일 수 있다.

그러나 미분 값이 0이면 가중치 매개변수를 어느 쪽으로 움직여도 손실 함수의 값은 줄어들지 않는다.
그래서 가중치 매개변수의 갱신은 그 시점에서 멈춘다.

신경망을 학습할 때 정확도를 지표로 삼아서는 안 된다.
정확도를 지표로 하면 매개변수의 미분이 대부분의 장소에서 0이 되기 때문이다.

1) 정확도를 지표로 삼은 경우, 불연속적인 값으로 바뀌어 버린다.-> 계단 함수
2) 손실 함수를 지표로 삼은 경우, 연속적인 값으로 구할 수 있다.-> 시그모이드 함수

계단 함수의 미분은 대부분의 장소에서 0이다.
-> 계단 함수를 이용하면 손실 함수를 지표로 삼는 게 아무 의미가 없게 된다.
-> 매개변수의 작은 변화가 주는 파장을 계단 함수가 말살하여 손실 함수의 값에는 아무런 변화가 나타나지 않게 된다.

계단 함수는 한순간만 변화를 일으키지만, 시그모이드 함수의 미분(접선)은 출력(세로축)이\
연속적으로 변하고 곡선의 기울기도 연속적으로 변한다.
-> 시그모이드 함수의 미분은 어느 장소라도 0이 되지는 않는다.
-> 신경망 학습에서 중요한 성질로, 기울기가 0이 되지 않는 덕분에 신경망이 올바르게 학습할 수 있는 것이다.
'''