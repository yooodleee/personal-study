#배치 정규화
'''
각 층이 활성화를 적당히 퍼뜨리도록 강제하는 경우-> 배치 정규화batch normalization

학습을 빨리 진행할 수 있다(학습 속도 개선)
초깃값에 크게 의존하지 않는다.(골치 아픈 초기값 선택 장애 개선)
오버피팅을 억제한다.(드롭아웃 등의 필요성 감소)

각 층에서의 활성화 값이 적당히 분포되도록 조정한다.
데이터 분포를 정규화하는 '배치 정규화'batch norm을 신경망에 삽입한다.

배치 정규화는 학습 시 미니배치를 단위로 정규화한다.
구체적으로는 데이터 분포가 평균이 0, 분산이 1이 되도록 정규화한다.

미니배치 B=[x_1, x_2, ..., x_m]이라는 m개의 입력 데이터의 집합에 대해\
평균과 분산을 구한다.
입력 데이터를 평균이 0, 분산이 1이 되게(적절한 분포가 되게) 정규화한다.
-> 활성화 함수의 앞(혹은 뒤)에 삽입함으로써 데이터 분포가 덜 치우치게 된다.

배치 정규화 계층마다 이 정규화된 데이터에 고유한 확대scale와 이동 shift 변환을 수행한다.
확대와 이동은 학습하면서 적합한 값으로 조정해간다.
(확대=1: 1배 확대, 이동=0: 이동하지 않았음-> 원본 그대로에서 시작함을 의미함)
'''
