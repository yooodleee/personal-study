#Adam
'''
모멘텀+Adagrad->매개변수 공간을 효율적으로 탐색가능, 하이퍼파라미터의 '편향 보정'이 진행됨.
모멘텀과 비슷한 페턴이지만, 모멘텀보다 공의 좌우 흔들림이 적다.
-> 학습의 갱신 강도를 적응적으로 조정해서 얻는 혜택이다.

하이퍼파라미터를 3개 설정한다.
하나는 학습률, 나머지 2개는 일차 모멘텀용 계수 beta_1, 이차 모멘텀용 계수 beta_2,\
기본 설정값은 beta_1=0.9, beta_2=0.999이며, 이 값이면 많은 경우에 좋은 결과를 얻을 수 있다.
'''