{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "#모듈 클래스 기본형\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1=nn.Conv2d(1, 20, 5)\n",
    "        self.conv2=nn.Conv2d(20, 20, 5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x=F.relu(self.conv1(x))\n",
    "        x=F.relu(self.conv2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#라이브러리 및 프레임워크 초기화\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#사용자 정의 데이터세트\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        df=pd.read_csv(file_path)\n",
    "        self.x=df.iloc[:, 0].values\n",
    "        self.y=df.iloc[:, 1].values\n",
    "        self.length=len(df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x=torch.FloatTensor([self.x[index]**2, self.x[index]])\n",
    "        y=torch.FloatTensor([self.y[index]])\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "#사용자 정의 모델\n",
    "class CustomModel(nn.Module):\n",
    "    def __int__(self):\n",
    "        super().__init__()\n",
    "        self.layer=nn.Linear(2, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x=self.layer(x)\n",
    "        return x\n",
    "\n",
    "#사용자 정의 데이터세트와 데이터로더\n",
    "train_dataset=CustomDataset('../datasets/non_linear.csv')\n",
    "train_dataloader=DataLoader(train_dataset, batch_size=128, shuffle=True, drop_last=True)\n",
    "\n",
    "#GPU 연산 적용\n",
    "device='cuda' if torch.cuda.is_available() else 'CPU'\n",
    "model=CustomModel().to(device)\n",
    "criterion=nn.MSELoss().to(device)\n",
    "optimizer=optim.SGD(model.parameters(), lr=0.0001)\n",
    "\n",
    "#학습 진행\n",
    "for epoch in range(10000):\n",
    "    cost=0.0\n",
    "\n",
    "    for x, y in train_dataloader:\n",
    "        x=x.to(device)\n",
    "        y=y.to(device)\n",
    "\n",
    "        output=model(x)\n",
    "        loss=criterion(output, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        cost+=loss\n",
    "    \n",
    "    cost=cost/len(train_dataloader)\n",
    "\n",
    "    if (epoch+1)%1000==0:\n",
    "        print(f'Epoch : {epoch+1:4d}, Model : {list(model.parameters())}, Cost : {cost:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 평가\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    inputs=torch.FloatTensor(\n",
    "        [\n",
    "            [1**2, 1],\n",
    "            [5**2, 5],\n",
    "            [11**2, 11]\n",
    "        ]\n",
    "    ).to(device)\n",
    "    outputs=model(inputs)\n",
    "    print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 저장\n",
    "torch.save(\n",
    "    model,\n",
    "    '../models/model.pt'\n",
    ")\n",
    "\n",
    "torch.save(\n",
    "    model.state_dict(),\n",
    "    '../models/model_state_dict.pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#비선형 회귀에 대한 전체 코드\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        df=pd.read_csv(file_path)\n",
    "        self.x=df.iloc[:, 0].values\n",
    "        self.y=df.iloc[:, 1].values\n",
    "        self.length=len(df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x=torch.FloatTensor([self.x[index]**2, self.x[index]])\n",
    "        y=torch.FloatTensor([self.y[index]])\n",
    "        return x, y\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x=self.layer(x)\n",
    "        return x\n",
    "    \n",
    "train_dataset=CustomDataset('../datasets/non_linear.csv')\n",
    "train_dataloader=DataLoader(train_dataset, batch_size=128, shuffle=True, drop_last=True)\n",
    "\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model=CustomModel().to(device)\n",
    "criterion=nn.MSELoss().to(device)\n",
    "optimizer=optim.SGD(model.parameters(), lr=0.0001)\n",
    "\n",
    "for epoch in range(10000):\n",
    "    cost=0.0\n",
    "\n",
    "    for x, y in train_dataloader:\n",
    "        x=x.to(device)\n",
    "        y=y.to(device)\n",
    "\n",
    "        output=model(x)\n",
    "        loss=criterion(output, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        cost+=loss\n",
    "    \n",
    "    cost=cost/len(train_dataloader)\n",
    "\n",
    "    if (epoch+1)%1000==0:\n",
    "        print(f'Epoch : {epoch+1:4d}, Model : {list(model.parameters())}, Cost : {cost:.3f}')\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    inputs=torch.FloatTensor(\n",
    "        [\n",
    "            [1**2, 1],\n",
    "            [5**2, 5],\n",
    "            [11**2, 11]\n",
    "        ]\n",
    "    ).to(device)\n",
    "    outputs=model(inputs)\n",
    "    print(outputs)\n",
    "\n",
    "torch.save(\n",
    "    model.state_dict(),\n",
    "    '../models/model_state_dict.pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터세트 분리\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "#중략\n",
    "\n",
    "dataset=CustomDataset('..datasets/non_linear.csv')\n",
    "dataset_size=len(dataset)\n",
    "train_size=int(dataset_size*0.8)\n",
    "validation_size=int(dataset_size*0.1)\n",
    "test_size=dataset_size-train_size-validation_size\n",
    "\n",
    "train_datset, validation_dataset, test_dataset=\\\n",
    "    random_split(dataset, [train_size, validation_size, test_size])\n",
    "print(f'Training Data Size : {len(train_dataset)}')\n",
    "print(f'Validation Data Size : {len(validation_dataset)}')\n",
    "print(f'Testing Data Size : {len(test_dataset)}')\n",
    "\n",
    "train_dataloader=DataLoader(train_dataset, batch_size=16, shuffle=True, drop_last=True)\n",
    "validation_dataloader=DataLoader(validation_dataset, batch_size=4, shuffle=True, drop_last=True)\n",
    "test_dataloader=DataLoader(test_dataset, batch_size=4, shuffle=True, drop_last=True)\n",
    "\n",
    "#중략\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    \n",
    "    for x, y in validation_dataloader:\n",
    "        x=x.to(device)\n",
    "        y=y.to(device)\n",
    "\n",
    "        outputs=model(x)\n",
    "        print(f'X : {x}')\n",
    "        print(f'Y : {y}')\n",
    "        print(f'Outputs : {outputs}')\n",
    "        print('----------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#무작위 분리 함수\n",
    "subset=torch.utils.data.random_split(\n",
    "    dataset,\n",
    "    lengths,\n",
    "    generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터세트 분리 방법\n",
    "dataset=CustomDataset('nonlinear.csv')\n",
    "datset_size=len(dataset)\n",
    "train_size=int(dataset_size*0.8)\n",
    "validation_size=int(dataset_size*0.1)\n",
    "test_size=dataset_size-train_size-validation_size\n",
    "\n",
    "train_dataset, validation_dataset, test_dataset=\\\n",
    "    random_split(dataset, [train_size, validation_size, test_size])\n",
    "print(f'Training Data Size : {len(train_dataset)}')\n",
    "print(f'Validation Data Size : {len(validation_dataset)}')\n",
    "print(f'Testing Data Size : {len(test_dataset)}')\n",
    "\n",
    "train_dataloader=DataLoader(train_dataset, batch_size=16, shuffle=True, drop_last=True)\n",
    "validation_dataloader=DataLoader(validation_dataset, batch_size=4, shuffle=True, drop_last=True)\n",
    "test_dataloader=DataLoader(test_dataset, batch_size=4, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#검증용 데이터세트를 통한 평가\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for x, y in validation_dataloader:\n",
    "        x=x.to(device)\n",
    "        y=y.to(device)\n",
    "\n",
    "        outputs=model(x)\n",
    "        print(f'X : {x}')\n",
    "        print(f'Y : {y}')\n",
    "        print(f'Outpus : {outputs}')\n",
    "        print('----------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 저장 함수\n",
    "torch.save(\n",
    "    model,\n",
    "    path\n",
    ")\n",
    "\n",
    "#모델 불러오기 함수\n",
    "model=torch.load(\n",
    "    path,\n",
    "    map_location\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 불러오가\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer=nn.Linear(2, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x=self.layer(x)\n",
    "        return x\n",
    "    \n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model=torch.load('../models/model.pt', map_location=device)\n",
    "print(model)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    inputs=torch.FloatTensor(\n",
    "        [\n",
    "            [1**2, 1],\n",
    "            [5**2, 5],\n",
    "            [11**2, 11]\n",
    "        ]\n",
    "    ).to(device)\n",
    "    outputs=model(inputs)\n",
    "    print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 구조 확인\n",
    "import torch \n",
    "from torch import nn\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    pass\n",
    "\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model=torch.load('../models/model.pt', map_location=device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 상태 저장\n",
    "torch.save(\n",
    "    model.state_dict(),\n",
    "    '../models/model_state_dict.pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 상태 불러오기\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer=nn.Linear(2, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x=self.layer(x)\n",
    "        return x\n",
    "\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model=CustomModel().to(device)\n",
    "\n",
    "model_state_dict=torch.load('../models/model_state_dict.pt', map_location=device)\n",
    "model.load_state_dict(model_state_dict)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    inputs=torch.FloatTensor(\n",
    "        [\n",
    "            [1**2, 1],\n",
    "            [5**2, 5],\n",
    "            [11**2, 11]\n",
    "        ]\n",
    "    ).to(device)\n",
    "    outputs=model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#체크포인트 저장\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#중략\n",
    "\n",
    "checkpoint=1\n",
    "for epoch in range(10000):\n",
    "    ...\n",
    "    cost=cost/len(train_dataloader)\n",
    "\n",
    "    if (epoch+1)%1000==0:\n",
    "        torch.save(\n",
    "            {\n",
    "                'model':'CustomModel',\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict' : model.state_dict(),\n",
    "                'optimizer_state_dict' : optimizer.state_dict(),\n",
    "                'cost' : cost,\n",
    "                'description' : f'CustomModel 체크포인트-{checkpoint}',\n",
    "            },\n",
    "            f'../models/checkpoint-{checkpoint}.pt',\n",
    "        )\n",
    "        checkpoint+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#체크포인트 불러오기\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#중략\n",
    "\n",
    "checkpoint=torch.load('../models/checkpoint-6.pt')\n",
    "model.state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "checkpoint_epoch=checkpoint['epoch']\n",
    "checkpoint_description=checkpoint['description']\n",
    "print(checkpoint_description)\n",
    "\n",
    "for epoch in range(checkpoint_epoch+1, 10000):\n",
    "    cost=0.0\n",
    "\n",
    "    for x, y in train_dataloader:\n",
    "        x=x.to(device)\n",
    "        y=y.to(device)\n",
    "\n",
    "        output=model(x)\n",
    "        loss=criterion(output, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        cost+=loss\n",
    "        if (epoch+1)%1000==0:\n",
    "            print(f'Epoch : {epoch+1:4d}, Model : {list(model.parameters())}, Cost : {cost:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#사용자 정의 데이터 세트\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        df=pd.read_csv(file_path)\n",
    "        self.x1=df.iloc[:, 0].values\n",
    "        self.x2=df.iloc[:, 1].values\n",
    "        self.x3=df.iloc[:, 2].values\n",
    "        self.y=df.iloc[:, 3].values\n",
    "        self.length=len(df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x=torch.FloatTensor([self.x1[index], self.x2[index], self.x3[index]])\n",
    "        y=torch.FloatTensor([self.y[index]])\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "#사용자 정의 모델\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer=nn.Sequential(\n",
    "            nn.Linear(3, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x=self.layer(x)\n",
    "        return x\n",
    "\n",
    "#이진 교차 엔트로피\n",
    "criterion=nn.BCELoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이진 분류\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        df=pd.read_csv(file_path)\n",
    "        self.x1=df.iloc[:, 0].values\n",
    "        self.x2=df.iloc[:, 1].values\n",
    "        self.x3=df.iloc[:, 2].values\n",
    "        self.y=df.iloc[:, 3].values\n",
    "        self.length=len(df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x=torch.FloatTensor([self.x1[index], self.x2[index], self.x3[index]])\n",
    "        y=torch.FloatTensor([self.y[index]])\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer=nn.Sequential(\n",
    "            nn.Linear(3, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x=self.layer(x)\n",
    "        return x\n",
    "\n",
    "dataset=CustomDataset('../datasets/binary.csv')\n",
    "dataset_size=len(dataset)\n",
    "train_size=int(dataset_size*0.8)\n",
    "validation_size=int(dataset_size*0.1)\n",
    "test_size=dataset_size-train_size-validation_size\n",
    "\n",
    "train_dataset, validation_dataset, test_dataset=random_split(\n",
    "    dataset, [train_size, validation_size, test_size], torch.manual_seed(4)\n",
    ")\n",
    "train_dataloader=DataLoader(train_dataset, batch_size=64, shuffle=True, drop_last=True)\n",
    "validation_dataloader=DataLoader(\n",
    "    validation_dataset, batch_size=4, shuffle=True, drop_last=True\n",
    ")\n",
    "test_dataloader=DataLoader(test_dataset, batch_size=4, shuffle=True, drop_last=True)\n",
    "\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model=CustomModel().to(device)\n",
    "criterion=nn.BCELoss().to(device)\n",
    "optimizer=optim.SGD(model.parameters(), lr=0.0001)\n",
    "\n",
    "for epoch in range(10000):\n",
    "    cost=0.0\n",
    "\n",
    "    for x, y in train_dataloader:\n",
    "        x=x.to(device)\n",
    "        y=y.to(device)\n",
    "\n",
    "        output=model(x)\n",
    "        loss=criterion(output, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        cost+=loss\n",
    "    \n",
    "    cost=cost/len(train_dataloader)\n",
    "\n",
    "    if (epoch+1)%1000==0:\n",
    "        print(f'Epoch : {epoch+1:4d}, Model : {list(model.parameters())}, Cost : {cost:.3f}')\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for x, y in validation_dataloader:\n",
    "        x=x.to(device)\n",
    "        y=y.to(device)\n",
    "\n",
    "        outputs=model(x)\n",
    "\n",
    "        print(outputs)\n",
    "        print(outputs >= torch.FloatTensor([0.5]).to(device))\n",
    "        print('-----------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 구조와 초깃값\n",
    "import torch \n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer1=nn.Sequential(\n",
    "            nn.Linear(2, 2),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.layer2=nn.Sequential(\n",
    "            nn.Linear(2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.layer1[0].weight.data=torch.nn.Parameter(\n",
    "            torch.Tensor([[0.4352, 0.3545],\n",
    "                          [0.1951, 0.4835]])\n",
    "        )\n",
    "\n",
    "        self.layer1[1].bias.data=torch.nn.Parameter(\n",
    "            torch.Tensro([-0.1419, 0.0439])\n",
    "        )\n",
    "\n",
    "        self.layer2[0].weight.data=torch.nn.Parameter(\n",
    "            torch.Tensor([[-0.1725, 0.1129]])\n",
    "        )\n",
    "\n",
    "        self.layer2[1].bias.data=torch.nn.Parameter(\n",
    "            torch.Tensor([-0.3043])\n",
    "        )\n",
    "\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model=CustomModel().to(device)\n",
    "criterion=nn.BCELoss().to(device)\n",
    "optimizer=optim.SGD(model.parameters(), lr=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#단층 퍼셉트론 구조\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        df=pd.read_csv(file_path)\n",
    "        self.x1=df.iloc[:, 0].values\n",
    "        self.x2=df.iloc[:, 1].values\n",
    "        self.y=df.iloc[:, 2].values\n",
    "        self.length=len(df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x=torch.FloatTensor([self.x1[index], self.x2[index]])\n",
    "        y=torch.FloatTensor([self.y[index]])\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.layer=nn.Sequential(\n",
    "            nn.Linear(2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x=self.layer(x)\n",
    "        return x\n",
    "\n",
    "train_dataset=CustomDataset('../datasets/perceptron.csv')\n",
    "train_dataloader=DataLoader(train_dataset, batch_size=64, shuffle=True, drop_last=True)\n",
    "\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model=CustomModel().to(device)\n",
    "criterion=nn.BCELoss().to(device)\n",
    "optimizer=optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(10000):\n",
    "    cost=0.0\n",
    "\n",
    "    for x, y in train_dataloader:\n",
    "        x=x.to(device)\n",
    "        y=y.to(device)\n",
    "\n",
    "        output=model(x)\n",
    "        loss=criterion(output, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        cost+=loss\n",
    "    \n",
    "    cost=cost/len(train_dataloader)\n",
    "\n",
    "    if (epoch+1)%1000==0:\n",
    "        print(f'Epoch : {epoch+1:4d}, Cost : {cost:.3f}')\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    inputs=torch.FloatTensor([\n",
    "        [0, 0],\n",
    "        [0, 1],\n",
    "        [1, 0],\n",
    "        [1, 1]\n",
    "    ]).to(device)\n",
    "    outputs=model(inputs)\n",
    "\n",
    "    print('--------')\n",
    "    print(outputs)\n",
    "    print(outputs <=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#다층 퍼셉트론 구조\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.layer1=nn.Sequential(\n",
    "            nn.Linear(2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.layer2=nn.Sequential(\n",
    "            nn.Linear(2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x=self.layer1(x)\n",
    "        x=self.layer2(x)\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
