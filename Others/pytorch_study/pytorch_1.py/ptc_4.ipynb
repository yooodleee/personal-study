{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['현실과', '구분', '불가능한', 'cg.', '시각적', '즐거움은', '최고!', '더불어', 'ost는', '더더욱', '최고!']\n"
     ]
    }
   ],
   "source": [
    "#단어 토큰화\n",
    "review='현실과 구분 불가능한 cg. 시각적 즐거움은 최고! 더불어 ost는 더더욱 최고!!'\n",
    "tokenized=review.split()\n",
    "print(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['현', '실', '과', ' ', '구', '분', ' ', '불', '가', '능', '한', ' ', 'c', 'g', '.', ' ', '시', '각', '적', ' ', '즐', '거', '움', '은', ' ', '최', '고', '!', ' ', '더', '불', '어', ' ', 'o', 's', 't', '는', ' ', '더', '더', '욱', ' ', '최', '고', '!', '!']\n"
     ]
    }
   ],
   "source": [
    "#글자 토큰화\n",
    "review='현실과 구분 불가능한 cg. 시각적 즐거움은 최고! 더불어 ost는 더더욱 최고!!'\n",
    "tokenized=list(review)\n",
    "print(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jamo import h2j\n",
    "import jamo\n",
    "#자모 변환 함수\n",
    "\n",
    "retval=jamo.h2j(\n",
    "    hangul_string=''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#한글 호환성 자모 변환 함수\n",
    "retval=jamo.j2hcj(\n",
    "    jamo\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ㅎ', 'ㅕ', 'ㄴ', 'ㅅ', 'ㅣ', 'ㄹ', 'ㄱ', 'ㅘ', ' ', 'ㄱ', 'ㅜ', 'ㅂ', 'ㅜ', 'ㄴ', ' ', 'ㅂ', 'ㅜ', 'ㄹ', 'ㄱ', 'ㅏ', 'ㄴ', 'ㅡ', 'ㅇ', 'ㅎ', 'ㅏ', 'ㄴ', ' ', 'c', 'g', '.', ' ', 'ㅅ', 'ㅣ', 'ㄱ', 'ㅏ', 'ㄱ', 'ㅈ', 'ㅓ', 'ㄱ', ' ', 'ㅈ', 'ㅡ', 'ㄹ', 'ㄱ', 'ㅓ', 'ㅇ', 'ㅜ', 'ㅁ', 'ㅇ', 'ㅡ', 'ㄴ', ' ', 'ㅊ', 'ㅚ', 'ㄱ', 'ㅗ', '!', ' ', 'ㄷ', 'ㅓ', 'ㅂ', 'ㅜ', 'ㄹ', 'ㅇ', 'ㅓ', ' ', 'o', 's', 't', 'ㄴ', 'ㅡ', 'ㄴ', ' ', 'ㄷ', 'ㅓ', 'ㄷ', 'ㅓ', 'ㅇ', 'ㅜ', 'ㄱ', ' ', 'ㅊ', 'ㅚ', 'ㄱ', 'ㅗ', '!', '!']\n"
     ]
    }
   ],
   "source": [
    "#자소 단위 토큰화\n",
    "from jamo import h2j, j2hcj\n",
    "\n",
    "review='현실과 구분 불가능한 cg. 시각적 즐거움은 최고! 더불어 ost는 더더욱 최고!!'\n",
    "decomposed=j2hcj(h2j(review))\n",
    "tokenized=list(decomposed)\n",
    "print(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "명사 추출 :  ['무엇', '상상', '수', '사람', '무엇', '낼', '수']\n",
      "구 추출 :  ['무엇', '상상', '상상할 수', '상상할 수 있는 사람', '사람']\n",
      "형태소 추출 :  ['무엇', '이든', '상상', '할', '수', '있는', '사람', '은', '무엇', '이든', '만들어', '낼', '수', '있다', '.']\n",
      "품사 태깅 :  [('무엇', 'Noun'), ('이든', 'Josa'), ('상상', 'Noun'), ('할', 'Verb'), ('수', 'Noun'), ('있는', 'Adjective'), ('사람', 'Noun'), ('은', 'Josa'), ('무엇', 'Noun'), ('이든', 'Josa'), ('만들어', 'Verb'), ('낼', 'Noun'), ('수', 'Noun'), ('있다', 'Adjective'), ('.', 'Punctuation')]\n"
     ]
    }
   ],
   "source": [
    "#Okt 토큰화\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "okt=Okt()\n",
    "\n",
    "sentence='무엇이든 상상할 수 있는 사람은 무엇이든 만들어 낼 수 있다.'\n",
    "\n",
    "nouns=okt.nouns(sentence)\n",
    "phrases=okt.phrases(sentence)\n",
    "morphs=okt.morphs(sentence)\n",
    "pos=okt.pos(sentence)\n",
    "\n",
    "print('명사 추출 : ', nouns)\n",
    "print('구 추출 : ', phrases)\n",
    "print('형태소 추출 : ', morphs)\n",
    "print('품사 태깅 : ', pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "명사 추출:  ['무엇', '상상', '수', '사람', '무엇']\n",
      "문장 추출:  ['무엇이든 상상할 수 있는 사람은 무엇이든 만들어 낼 수 있다.']\n",
      "형태소 추출:  ['무엇', '이', '든', '상상', '하', 'ㄹ', '수', '있', '는', '사람', '은', '무엇', '이', '든', '만들', '어', '내', 'ㄹ', '수', '있', '다', '.']\n",
      "품사 태깅:  [('무엇', 'NNG'), ('이', 'VCP'), ('든', 'ECE'), ('상상', 'NNG'), ('하', 'XSV'), ('ㄹ', 'ETD'), ('수', 'NNB'), ('있', 'VV'), ('는', 'ETD'), ('사람', 'NNG'), ('은', 'JX'), ('무엇', 'NP'), ('이', 'VCP'), ('든', 'ECE'), ('만들', 'VV'), ('어', 'ECD'), ('내', 'VXV'), ('ㄹ', 'ETD'), ('수', 'NNB'), ('있', 'VV'), ('다', 'EFN'), ('.', 'SF')]\n"
     ]
    }
   ],
   "source": [
    "#꼬꼬마 토큰화\n",
    "from konlpy.tag import Kkma\n",
    "\n",
    "kkma=Kkma()\n",
    "\n",
    "sentence='무엇이든 상상할 수 있는 사람은 무엇이든 만들어 낼 수 있다.'\n",
    "\n",
    "nouns=kkma.nouns(sentence)\n",
    "sentences=kkma.sentences(sentence)\n",
    "morphs=kkma.morphs(sentence)\n",
    "pos=kkma.pos(sentence)\n",
    "\n",
    "print('명사 추출: ', nouns)\n",
    "print('문장 추출: ', sentences)\n",
    "print('형태소 추출: ', morphs)\n",
    "print('품사 태깅: ', pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dhals_zn0ga5j\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\dhals_zn0ga5j\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#패키지 및 모델 다운로드\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Those', 'who', 'can', 'imagine', 'anything', ',', 'can', 'create', 'the', 'impossible', '.']\n",
      "['Those who can imagine anything, can create the impossible.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dhals_zn0ga5j\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\dhals_zn0ga5j\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\dhals_zn0ga5j\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#패키지 및 모델 다운로드\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "#영문 토큰화화\n",
    "from nltk import tokenize\n",
    "\n",
    "sentence='Those who can imagine anything, can create the impossible.'\n",
    "\n",
    "word_tokens=tokenize.word_tokenize(sentence)\n",
    "sent_tokens=tokenize.sent_tokenize(sentence)\n",
    "\n",
    "print(word_tokens)\n",
    "print(sent_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dhals_zn0ga5j\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\dhals_zn0ga5j\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\dhals_zn0ga5j\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\dhals_zn0ga5j\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger_eng.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Those', 'DT'), ('who', 'WP'), ('can', 'MD'), ('imagine', 'VB'), ('anything', 'NN'), (',', ','), ('can', 'MD'), ('create', 'VB'), ('the', 'DT'), ('impossible', 'JJ'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "#패키지 및 모델 다운로드\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "\n",
    "#영문 품사 태깅\n",
    "from nltk import tag\n",
    "from nltk import tokenize\n",
    "\n",
    "sentence='Those who can imagine anything, can create the impossible.'\n",
    "\n",
    "word_tokens=tokenize.word_tokenize(sentence)\n",
    "pos=tag.pos_tag(word_tokens)\n",
    "\n",
    "print(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PRON -DT ]:Those\n",
      "[PRON -WP ]:who\n",
      "[AUX  -MD ]:can\n",
      "[VERB -VB ]:imagine\n",
      "[PRON -NN ]:anything\n",
      "[PUNCT-,  ]:,\n",
      "[AUX  -MD ]:can\n",
      "[VERB -VB ]:create\n",
      "[DET  -DT ]:the\n",
      "[ADJ  -JJ ]:impossible\n",
      "[PUNCT-.  ]:.\n"
     ]
    }
   ],
   "source": [
    "#spaCy 품사 태깅\n",
    "import spacy\n",
    "\n",
    "nlp=spacy.load('en_core_web_sm')\n",
    "sentence='Those who can imagine anything, can create the impossible.'\n",
    "doc=nlp(sentence)\n",
    "\n",
    "for token in doc:\n",
    "    print(f'[{token.pos_:5}-{token.tag_:3}]:{token.text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Korpora 는 다른 분들이 연구 목적으로 공유해주신 말뭉치들을\n",
      "    손쉽게 다운로드, 사용할 수 있는 기능만을 제공합니다.\n",
      "\n",
      "    말뭉치들을 공유해 주신 분들에게 감사드리며, 각 말뭉치 별 설명과 라이센스를 공유 드립니다.\n",
      "    해당 말뭉치에 대해 자세히 알고 싶으신 분은 아래의 description 을 참고,\n",
      "    해당 말뭉치를 연구/상용의 목적으로 이용하실 때에는 아래의 라이센스를 참고해 주시기 바랍니다.\n",
      "\n",
      "    # Description\n",
      "    Author : Hyunjoong Kim lovit@github\n",
      "    Repository : https://github.com/lovit/petitions_archive\n",
      "    References :\n",
      "\n",
      "    청와대 국민청원 게시판의 데이터를 월별로 수집한 것입니다.\n",
      "    청원은 게시판에 글을 올린 뒤, 한달 간 청원이 진행됩니다.\n",
      "    수집되는 데이터는 청원종료가 된 이후의 데이터이며, 청원 내 댓글은 수집되지 않습니다.\n",
      "    단 청원의 동의 개수는 수집됩니다.\n",
      "    자세한 내용은 위의 repository를 참고하세요.\n",
      "\n",
      "    # License\n",
      "    CC0 1.0 Universal (CC0 1.0) Public Domain Dedication\n",
      "    Details in https://creativecommons.org/publicdomain/zero/1.0/\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[korean_petitions] download petitions_2017-08: 1.84MB [00:00, 2.45MB/s]                            \n",
      "[korean_petitions] download petitions_2017-09: 20.4MB [00:04, 4.73MB/s]                            \n",
      "[korean_petitions] download petitions_2017-10: 12.0MB [00:02, 4.86MB/s]                            \n",
      "[korean_petitions] download petitions_2017-11: 28.4MB [00:07, 3.96MB/s]                            \n",
      "[korean_petitions] download petitions_2017-12: 29.0MB [00:14, 2.07MB/s]                            \n",
      "[korean_petitions] download petitions_2018-01: 43.9MB [00:12, 3.63MB/s]                            \n",
      "[korean_petitions] download petitions_2018-02: 33.8MB [00:07, 4.38MB/s]                            \n",
      "[korean_petitions] download petitions_2018-03: 34.3MB [00:09, 3.58MB/s]                            \n",
      "[korean_petitions] download petitions_2018-04: 35.5MB [00:07, 4.51MB/s]                            \n",
      "[korean_petitions] download petitions_2018-05: 37.5MB [00:09, 4.16MB/s]                            \n",
      "[korean_petitions] download petitions_2018-06: 37.8MB [00:08, 4.71MB/s]                            \n",
      "[korean_petitions] download petitions_2018-07: 40.5MB [00:08, 4.96MB/s]                            \n",
      "[korean_petitions] download petitions_2018-08: 39.8MB [00:10, 3.74MB/s]                            \n",
      "[korean_petitions] download petitions_2018-09: 36.1MB [00:08, 4.17MB/s]                            \n",
      "[korean_petitions] download petitions_2018-10: 38.1MB [00:09, 4.16MB/s]                            \n",
      "[korean_petitions] download petitions_2018-11: 37.7MB [00:08, 4.19MB/s]                            \n",
      "[korean_petitions] download petitions_2018-12: 33.0MB [00:09, 3.61MB/s]                            \n",
      "[korean_petitions] download petitions_2019-01: 34.8MB [00:07, 4.61MB/s]                            \n",
      "[korean_petitions] download petitions_2019-02: 30.8MB [00:05, 5.38MB/s]                            \n",
      "[korean_petitions] download petitions_2019-03: 34.9MB [00:08, 4.21MB/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "청원 시작일 :  2017-08-25\n",
      "청원 종료일 :  2017-09-24\n",
      "청원 동의 수 :  88\n",
      "청원 범주 :  육아/교육\n",
      "청원 제목 :  학교는 인력센터, 취업센터가 아닙니다. 정말 간곡히 부탁드립니다.\n",
      "청원 본문 :  안녕하세요. 현재 사대, 교대 등 교원양성학교들의 예비\n"
     ]
    }
   ],
   "source": [
    "#청와대 청원 데이터 다운로드\n",
    "from Korpora import Korpora\n",
    "\n",
    "corpus=Korpora.load('korean_petitions')\n",
    "dataset=corpus.train\n",
    "petition=dataset[0]\n",
    "\n",
    "print('청원 시작일 : ', petition.begin)\n",
    "print('청원 종료일 : ', petition.end)\n",
    "print('청원 동의 수 : ', petition.num_agree)\n",
    "print('청원 범주 : ', petition.category)\n",
    "print('청원 제목 : ', petition.title)\n",
    "print('청원 본문 : ', petition.text[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습 데이터세트 생성\n",
    "from Korpora import Korpora\n",
    "\n",
    "corpus=Korpora.load('korean_petitions')\n",
    "petitions=corpus.get_all_texts()\n",
    "with open('../datasets/corpus.txt', 'w', encoding='utf-8') as f:\n",
    "    for petition in petitions:\n",
    "        f.write(petition+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#토크나이저 모델 학습\n",
    "from sentencepiece import SentencePieceTrainer\n",
    "\n",
    "SentencePieceTrainer.Train(\n",
    "    '--input=../datasets/corpus.txt\\\n",
    "        --model_prefix=petitions_bpe\\\n",
    "            --vocab_size=8000 model_type=bpe'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentencepiece import SentencePieceProcessor\n",
    "\n",
    "SentencePieceProcessor().mo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#바이트 페어 인코딩 토큰화\n",
    "from sentencepiece import SentencePieceProcessor\n",
    "\n",
    "tokenizer=SentencePieceProcessor()\n",
    "tokenizer.load('petition_bpe.model')\n",
    "\n",
    "sentence='안녕하세요, 토크나이저가 잘 학습되었군요!'\n",
    "sentences=['이렇게 입력값을 리스트로 받아서', '쉽게 토크나이저를 사용할 수 있답니다']\n",
    "\n",
    "tokenized_sentence=tokenizer.encode_as_pieces(sentence)\n",
    "tokenized_sentences=tokenizer.encode_as_pieces(sentences)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
