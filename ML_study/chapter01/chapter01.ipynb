{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1부 머신러닝**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1장 한눈에 보는 머신러닝**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "얼마 전까지만 해도 집으로 가는 길을 휴대폰에 물어봐도 아무런 대답을 듣지 못할 뿐만 아니라 사람들이 우리들의 정신 상태를 의심했을 것이다.\n",
    "하지만 사실 머신러닝은 광학 문자 판독기(Optical Character Recognition; OCR) 같은 특별한 애플리케이션의 형태로 수십 년 동안 사용되었다.\n",
    "수억 명의 생활을 편리하게 만들어 주류가 된 첫 번째 머신러닝 애플리케이션은 1990년대에 시작되었다.\n",
    "바로 스팸 필터(spam filter)이다.\n",
    "자아가 있는 로봇까지는 아니지만 기술적으로 머신러닝이라 할 수 있다.\n",
    "실제로 잘 학습되어 있어서 이메일을 스팸으로 신고할 일이 거의 없어졌다.\n",
    "이후 수백 개의 머신러닝 애플리케이션이 우리가 매일 사용하는 많은 제품과 기능을 소리 없이 향상시켰다.\n",
    "음성 비서, 자동 번역, 이미지 검색, 제품 추천 등 아주 많다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "머신러닝은 어디서 시작하고 어디서 끝나는 것일까?\n",
    "'기계가 배운다'는 것이 정확히 무엇을 의미하는 것일까?\n",
    "위키백과 문서를 내려받으면 내 컴퓨터가 실제로 무언가를 배울 수 있을까?\n",
    "컴퓨터가 갑자기 똑똑해질 수 있을까?\n",
    "머신러닝이 무엇인지, 왜 머신러닝이 필요한지 살펴보면서 이 장을 시작하겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "머신러닝을 배우기 전에 머신러닝을 전체적으로 조망하고 주요 영역과 가장 중요한 랜드마크인 지도 학습과 비지도 학습(그리고 준지도 학습과 자기 지도 학습), 온라인 학습과 배치 학습, 사례 기반 학습과 모델 기반 학습을 알아보겠다.\n",
    "또한 전형적인 머신러닝 프로젝트의 작업 흐름을 살펴보고 만날 수 있는 주요 문제점과 머신러닝 시스템을 평가하고 세밀하고 튜닝하는 방법을 다루겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 장에서 모든 데이터 과학자가 꼭 알아야 할 여러 가지 기초 개념과 용어를 소개한다.\n",
    "거시적인 소개를 담고 있으며 코드가 많지 않은 유일한 장이다.\n",
    "간단한 내용이지만 머신러닝을 깊이 다루기 이전에 모든 내용을 완벽하게 이해해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1.1 머신러닝이란?**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스팸 필터는 (사용자가 스팸이라고 지정한) 스팸 메일과 일반 메일의 데이터를 이용해 스팸 메일 구분법을 배울 수 있는 머신러닝 프로그램이다.\n",
    "시스템이 학습하는 데 사용하는 샘플을 훈련 세트(training set)라고 하고 각각의 훈련 데이터를 훈련 사례(training instance) (혹은 샘플sample)라고 한다.\n",
    "머신러닝 시스템에서 학습하고 예측을 만드는 부분은 모델(model)이라 부른다.\n",
    "모델의 예로는 신경망(neural network)이나 랜덤 포레스트(random forest)가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 경우 작업 T는 새로운 메일이 스팸인지 구분하는 것이고, 경험 E는 훈련 데이터(training data)이며, 성능 측정 p는 직접 정의해야 한다.\n",
    "예컨대 정확히 분류된 메일의 비율을 p로 사용할 수 있다.\n",
    "이 성능 측정을 정확도(accuracy)라고 부르며 분류 작업에 자주 사용된다.\n",
    "\n",
    "위키백과 문서를 모두 내려받으면 우리의 컴퓨터는 아주 많은 데이터를 갖게 된다.\n",
    "그렇다고 해서 어떤 작업이 갑자기 좋아지는 것은 아니다.\n",
    "그러므로 이는 머신러닝이 아니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1.2 왜 머신러닝을 사용할까?**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전통적인 프로그래밍 기법을 사용해 어떻게 스팸 필터를 만들 수 있을지 생각해보자.\n",
    "\n",
    "1. 먼저 스팸에 어떤 단어들이 주로 나타나는지 살펴본다. 그러면 '4U', '신용카드', '무료', '굉장한' 같은 단어나 구절이 제목에 많이 나타나는 경향이 있다는 것을 알 수 있다. 어쩌면 보낸이의 이름이나 본문, 이메일의 다른 요소에서 다른 패턴을 감지할 수도 있다.\n",
    "2. 발견한 패턴을 감지하는 알고리즘을 작성하여 프로그램이 이런 패턴을 발견했을 때 그 메일을 스팸으로 분류하게 한다.\n",
    "3. 프로그램을 테스트하고 론칭할 만큼 충분한 성능이 나올 때까지 1단계와 2단계를 반복한다.\n",
    "\n",
    "문제가 어렵기 때문에 규칙이 점점 길고 복잡해지므로 유지 보수하기 매우 힘들어진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "반면 머신러닝 기법에 기반을 둔 스팸 필터는 일반 메일에 비해 스팸에 자주 나타나는 패턴을 감지하여 어떤 단어와 구절이 스팸 메일을 판단하는 데 좋은 기준인지 자동으로 학습한다.\n",
    "그러므로 프로그램이 훨씬 짧아지고 유지 보수하기 쉬우며 대부분 정확도가 더 높다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "머신러닝이 유용한 또 다른 분야는 전통적인 방식으로는 너무 복잡하거나 알려진 알고리즘이 없는 문제이다.\n",
    "음성 인식(speech recognition)을 예로 들 수 있다.\n",
    "'one'과 'two' 두 단어를 구분하는 프로그램을 작성한다고 하자.\n",
    "단어 'two'는 높은 피치(pitch)의 사운드('T')로 시작하므로 높은 피치의 사운드 강도를 측정하는 알고리즘을 하드코딩해서 'one'과 'two'를 구분할 수도 있다.\n",
    "당연히 이 방법은 소음이 있는 환경에서 수백만 명이 여러 언어로 말하는 수천 개의 단어를 구분하도록 확장하기 어렵다.\n",
    "각 단어를 녹음한 샘플을 사용해 스스로 학습하는 알고리즘을 작성하는 것이 현재 가장 좋은 솔루션일 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리는 머신러닝을 통해 배울 수도 있다.\n",
    "즉, 머신러닝 알고리즘이 학습한 것을 조사할 수 있다(어떤 알고리즘은 이렇게 하기 어렵다).\n",
    "예컨대 스팸 필터가 충분한 스팸 메일로 훈련되었다면 스팸을 예측하는 데 가장 좋은 단어 및 단어의 조합이 무엇인지 확인할 수 있다.\n",
    "가끔 예상치 못한 상관관계나 새로운 추세가 발견되기도 해서 해당 문제를 더 잘 이해하도록 도와준다.\n",
    "대용량의 데이터를 분석하여 숨겨진 패턴을 발견하는 것을 데이터 마이닝(data mining)이라고 한다.\n",
    "머신러닝은 이런 작업에 뛰어나다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1.3 머신러닝 시스템의 종류**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "머신러닝 시스템의 종류는 굉장히 많으므로 넓은 범주에서 분류하면 도움이 된다.\n",
    "\n",
    "* 훈련 지도 방식(지도/비지도/준지도/자기 지도/강화 학습)\n",
    "* 실시간으로 점진적인 학습을 하는지 아닌지(온라인 학습/배치 학습)\n",
    "* 단순하게 알고 있는 데이터 포인트와 새 데이터 포인트를 비교하는 것인지 아니면 과학자들이 하는 것처럼 훈련 데이터셋에서 패턴을 발견하여 예측 모델을 만드는지(사례 기반 학습/모델 기반 학습)\n",
    "\n",
    "이 범주들은 서로 배타적이지 않으며 원하는 대로 연결할 수 있다.\n",
    "예컨대 최첨단 스팸 필터가 심층 신경망 모델을 사용해 스팸과 스팸이 아닌 메일로부터 실시간으로 학습할지도 모른다.\n",
    "그렇다면 이 시스템은 온라인이고 모델 기반이며 지도 학습 시스템이다.\n",
    "\n",
    "이 범주들을 조금 더 자세히 들여다보겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **1.4.1 훈련 지도 방식**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "머신러닝 시스템을 학습하는 동안의 지도 형태나 정보량에 따라 분류할 수 있다.\n",
    "많은 종류가 있지만 지도/비지도/준지도/자기 지도/강화 학습에 대해 알아보겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **지도 학습**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지도 학습(supervised learning)에서는 알고리즘에 주입하는 훈련 데이터에 레이블(label)이라는 원하는 답이 포함된다.\n",
    "분류(classification)가 전형적인 지도 학습이며, 스팸 필터가 좋은 예이다.\n",
    "스팸 필터는 많은 샘플 이메일과 클래스(class)(스팸인지 아닌지)로 훈련되며 어떻게 새 메일을 분류할지 학습해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "또 다른 전형적인 작업은 특성(feature)(주행 거리, 연식, 브랜드 등)을 사용해 중고차 가격 같은 타깃(target) 수치를 예측하는 것이다.\n",
    "이런 종류의 작업을 회귀(regression)라고 부른다.\n",
    "시스템을 훈련하려면 특성과 타깃(중고차 가격)이 포함된 중고차 데이터가 많이 필요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 지도 학습에서 타깃과 레이블은 일반적으로 동의어로 취급되지만, 타깃은 회귀 작업에서 많이 사용되고 레이블은 분류 작업에서 많이 사용된다. 또한 특성은 예측 변수(predictor)나 속성(attribute)이라고도 부른다. 이런 용어는 개별 샘플 또는 모든 샘플을 의미할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일부 알고리즘을 분류에 사용할 수도 있다.\n",
    "반대로 일부 분류 알고리즘을 회귀에 사용할 수도 있다.\n",
    "예컨대 분류에 널리 쓰이는 로지스틱 회귀(Logistic Regression)는 클래스에 속할 확률을 출력한다(스팸일 가능성 20%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **비지도 학습**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "비지도 학습(unsupervised learning)에서는 말 그대로 훈련 데이터에 레이블이 없다.\n",
    "시스템이 아무런 도움 없이 학습해야 함을 의미한다.\n",
    "\n",
    "예컨대 블로그 방문자에 대한 데이터가 많이 있다고 하자.\n",
    "비슷한 방문자들을 그룹으로 묶기 위해 군집(clustering) 알고리즘을 적용하려 한다.\n",
    "하지만 방문자가 어떤 그룹에 속하는지 알고리즘에 알려줄 수 있는 정보가 없다.\n",
    "그래서 알고리즘이 스스로 방문자 사이의 연결고리를 찾는다.\n",
    "예컨대 40%의 방문자는 만화책을 좋아하며 방과후에 블로그에 방문하는 10대이고, 20%는 SF를 좋아하고 주말에 방문하는 성인임을 알게 될지도 모른다.\n",
    "계층 군집(hierarchical clustering) 알고리즘을 사용하면 각 그룹을 더 작은 그룹으로 세분화할 수 있다.\n",
    "그러면 각 그룹에 맞춰 블로그에 글을 쓰는 데 도움이 될 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시각화(visualization) 알고리즘도 비지도 학습의 좋은 예이다.\n",
    "레이블이 없는 대규모의 고차원 데이터를 넣으면 도식화가 가능한 2D나 3D 표현을 만들어준다.\n",
    "이런 알고리즘은 가능한 한 구조를 그대로 유지하려 하므로 (예컨대 입력 공간에서 떨어져 있던 클러스터는 시각화된 그래프에서 겹쳐지지 않게 유지된다) 데이터가 어떻게 조직되어 있는지 이해할 수 있고 예상치 못한 패턴을 발견할 수도 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "비슷한 작업으로는 너무 많은 정보를 잃지 않으면서 데이터를 간소화하려는 차원 축소(dimensioanlly reduction)가 있다.\n",
    "이렇게 하는 한 가지 방법은 상관 관계가 있는 여러 특성을 하나로 합치는 것이다.\n",
    "예컨대 차의 주행 거리는 연식과 강하게 연관되어 있기 때문에 차원 축소 알고리즘으로 두 특성을 차의 마모 정도를 나타내는 하나의 특성으로 합칠 수 있다.\n",
    "이를 특성 추출(feature extraction)이라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* (지도 학습 알고리즘 같은) 머신러닝 알고리즘에 데이터를 주입하기 전에 차원 축소 알고리즘을 사용하여 훈련 데이터에 있는 차원의 수를 줄이는 것이 유용할 때가 많다. 실행 속도가 훨씬 빨라지고 디스크와 메모리를 차지하는 공간도 줄어든다. 경우에 따라 성능이 좋아지기도 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "또 하나의 중요한 비지도 학습은 이상치 탐지(outlier detection)이다.\n",
    "예컨대 부정 거래를 막기 위해 신용카드 거래를 감지하고, 제조 결함을 잡아내고, 학습 알고리즘에 주입하기 전에 데이터셋에서 이상한 값을 자동으로 제거하는 것 등이다.\n",
    "시스템은 훈련하는 동안 대부분 정상 샘플을 만나 이를 인식하도록 훈련된다.\n",
    "그 다음 새로운 샘플을 보고 정상 데이터인지 혹은 이상치인지 판단한다.\n",
    "매우 비슷한 작업으로 특이치 탐지(novelty detection)가 있다.\n",
    "훈련 세트에 있는 모든 샘플과 달라 보이는 새로운 샘플을 탐지하는 것이 목적이다.\n",
    "따라서 알고리즘으로 감지하고 싶은 샘플을 모두 제거한 매우 '깨끗한' 훈련 세트가 필요하다.\n",
    "예컨대 강아지 사진 수천 장이 있고 그중 1%가 치와와 사진이라면 특이치 탐지 알고리즘은 새로운 치와와 사진을 특이치로 처리하지 못한다.\n",
    "반면 이상치 탐지 알고리즘은 치와와가 매우 드물고 다른 강아지와 다르다고 인식하여 이상치로 분류할 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "널리 사용되는 또 다른 비지도 학습은 대용량 데이터에서 특성 간의 흥미로운 관계를 찾는 연관 규칙 학습(association rule learning)이다.\n",
    "예를 들어 슈퍼마켓을 운영한다고 가정해보자.\n",
    "판매 기록에 연관 규칙을 적용하면 바베큐 소스와 감자를 구매한 사람이 스테이크도 구매하는 경향이 있다는 것을 찾을지도 모른다.\n",
    "그렇다면 아마 이 상품들을 서로 가까이 진열하고 싶을 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **준지도 학습**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터에 레이블을 다는 것은 일반적으로 시간과 비용이 많이 들기 때문에 레이블이 없는 샘플이 많고 레이블된 샘플은 적은 경우가 많다.\n",
    "어떤 알고리즘은 레이블이 일부만 있는 데이터를 다룰 수 있는데, 이를 준지도 학습(semi-supervised learning)이라고 한다.\n",
    "\n",
    "구글 포토 서비스가 좋은 예이다.\n",
    "이 서비스에 가족 사진을 모두 올리면 사람 A는 사진1, 5, 11에 있고 사람 B는 사진 2, 5, 7에 있다고 자동으로 인식한다.\n",
    "이는 비지도 학습(군집)이다.\n",
    "이제 시스템에 필요한 것은 이 사람들이 누구인가 하는 정보이다.\n",
    "사람마다 레이블을 하나만 추가하면 사진에 있는 모든 사람의 이름을 알 수 있고, 편리하게 사진을 찾을 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "대부분의 준지도 학습 알고리즘은 지도 학습과 비지도 학습의 조합으로 이루어져 있다.\n",
    "예를 들어 군집 알고리즘을 사용해 비슷한 샘플을 한 그룹으로 모은다.\n",
    "그 다음 레이블이 없는 샘플에 클러스터에서 가장 많이 등장하는 레이블을 할당한다.\n",
    "전체 데이터셋에 레이블이 부여되고 나면 지도 학습 알고리즘을 사용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **자기 지도 학습**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "또 다른 머신러닝 방법은 레이블이 전혀 없는 데이터셋에서 레이블이 완전히 부여된 데이터셋을 생성하는 것이다.\n",
    "여기서도 전체 데이터셋이 레이블이 부여되고 나면 어떤 지도 학습 알고리즘도 사용할 수 있다.\n",
    "이런 방법을 자기 지도 학습(self-supervised learning)이라고 부른다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예를 들어 레이블이 없는 이미지로 구성된 대량의 데이터셋이 있다면 각 이미지의 일부분을 랜덤하게 마스킹(masking)하고 모델이 원본 이미지를 복원하도록 훈련할 수 있다.\n",
    "훈련하는 동안 마스킹된 이미지는 모델의 입력으로 사용되고 원본 이미지는 레이블로 사용된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련된 모델은 그 자체로 매우 유용하다.\n",
    "예를 들어 손상된 이미지를 복원하거나 사진에서 원치 않는 물체를 삭제할 수 있다.\n",
    "하지만 종종 자기 지도 학습을 사용해 훈련된 모델이 최종 목적이 아닌 경우가 많다.\n",
    "일반적으로 조금 다르지만 실제 관심 대상인 작업을 위해 모델을 수정하거나 미세 튜닝(fine-tunning)한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예를 들면 반려동물 분류 모델이 필요하다고 가정해보자.\n",
    "반려동물 사진이 주어지면 모델은 어떤 품종인지 예측해야 한다.\n",
    "레이블이 없는 반려동물 사진으로 구성된 대량의 데이터셋이 있다면 자기 지도 학습을 사용하여 이미지 복원 모델을 먼저 훈련할 수 있다.\n",
    "훈련이 잘 되고나면 모델이 여러 종류의 반려동물을 구별할 수 있어야 한다.\n",
    "고양이 사진에서 마스킹된 얼굴을 복원할 때 강아지 얼굴을 넣어서는 안 되기 때문이다.\n",
    "모델 구조가 허락한다면 (대부분의 신경망 구조가 가능하지만) 이미지 복원 대신 반려동물 종류를 예측하도록 모델을 수정할 수 있다.\n",
    "마지막 단계는 레이블이 있는 데이터셋에서 모델을 미세 튜닝하는 것이다.\n",
    "이 모델은 고양이, 강아지 그리고 다른 종류의 반려동물이 어떻게 생겼는지 이미 알고있다.\n",
    "따라서 이 단계는 모델이 이미 알고 있는 동물과 기대하는 레이블을 매핑하는 방법을 학습할 뿐이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 한 작업에서 다른 작업으로 지식을 전달하는 것을 전이 학습(transfer learning)이라고 부른다. 오늘날 머신러닝 분야, 특히 심층 신경망(deep neural network)(즉, 뉴런neuron의 층layer이 여러 개인 신경망)을 사용할 때 가장 중요한 기술이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **강화 학습**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "강화 학습(reinforcement learning)은 매우 다른 종류의 알고리즘이다.\n",
    "여기서는 학습하는 시스템을 에이전트(agent)라고 부르며 환경(environment)을 관찰해서 행동(action)을 실행하고 그 결과를 보상(reward)을 받는다.\n",
    "시간이 지나면서 가장 큰 보상을 얻기 위해 정책(policy)이라고 부르는 최상의 전략을 스스로 학습한다.\n",
    "정책은 주어진 상황에서 에이전트가 어떤 행동을 선택할지 정의한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1.4.2 배치 학습과 온라인 학습**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "머신러닝 시스템을 분류하는 데 사용하는 다른 기준은 입력 데이터의 스트림(stream)으로부터 점진적으로 학습할 수 있는지 여부이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **배치 학습**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "배치 학습(batch learning)에서는 시스템이 점진적으로 학습할 수 없다.\n",
    "가용한 데이터를 모두 사용해 훈련시켜야 한다.\n",
    "일반적으로 이 방식은 시간과 자원을 많이 소모하므로 오프라인에서 수행된다.\n",
    "먼저 시스템을 훈련시킨 다음 제품 시스템에 적용하면 더 이상의 학습 없이 실행된다.\n",
    "즉, 학습한 것을 단지 적용만 한다,\n",
    "이를 오프라인 학습(offline learning)이라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "불행히도 모델의 성능은 시간이 지남에 따라 천천히 감소하는 경향이 있다.\n",
    "세상은 계속 진화하는데 모델은 바뀌지 않고 그대로이기 때문이다.\n",
    "이런 현상을 모델 부패(model rot) 또는 데이터 드리프트(data drift)라고 부른다.\n",
    "이에 대한 해결 방법은 최신 데이터에서 모델을 정기적으로 재훈련하는 것이다.\n",
    "얼마나 자주 재훈련해야 하는지는 경우에 따라 다르다.\n",
    "고양이와 강아지 사진을 분류하는 모델이라면 성능이 매우 느리게 감소할 것이다.\n",
    "모델이 금융 시장 같이 빠르게 진화하는 시스템에 대한 예측을 만든다면 성능이 매우 빠르게 나빠질 가능성이 많다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "배치 학습 시스템이 (새로운 종류의 스팸 같은) 새로운 데이터에 대해 학습하려면 (새로운 데이터뿐만 아니라 이전 데이터도 포함한) 전체 데이터를 사용하여 시스템의 새로운 버전을 처음부터 다시 훈련해야 한다.\n",
    "그런 다음 이전 모델을 새 모델로 교체한다.\n",
    "다행히 머신러닝 시스템을 훈련, 평가, 론칭하는 전체 과정이 쉽게 자동화될 수 있어서 배치 학습 시스템도 변화에 적응할 수 있다.\n",
    "데이터를 업데이트하고 시스템의 새 버전을 필요한 만큼 자주 훈련시키면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이런 방식은 간단하고 잘 작동하지만 전체 데이터셋을 사용해 훈련하는 데 몇 시간이 소요될 수 있다.\n",
    "보통 24시간마다 또는 매주 시스템을 훈련시킨다.\n",
    "시스템이 빠르게 변하는 데이터에 적응해야 한다면 (e.g. 주식 가격) 더 능동적인 방법이 필요하다.\n",
    "\n",
    "또한 전체 데이터셋을 사용해 훈련한다면 많은 컴퓨팅 작업이 필요하다(CPU, 메모리 공간, 디스크 공간, 디스크 IO, 네트워크 IO 등).\n",
    "대량의 데이터를 가지고 있는데 매일 처음부터 새로 훈련시키도록 시스템을 자동화한다면 많은 비용이 발생할 것이다.\n",
    "데이터 양이 아주 많으면 배치 학습 알고리즘을 사용하는 게 불가능할 수도 있다.\n",
    "\n",
    "마지막으로 자원이 제한된 시스템(e.g. 스마트폰 또는 화성 탐사 로버)이 스스로 학습해야 할 때 많은 양의 훈련 데이터를 나르고 매일 몇 시간씩 학습을 위해 많은 자원을 사용하면 심각한 문제를 일으킨다.\n",
    "이런 경우에는 점진적으로 학습할 수 있는 알고리즘을 사용하는 편이 낫다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **온라인 학습**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "온라인 학습(online learning)에서는 데이터를 순차적으로 한 개씩 또는 미니배치(mini-batch)라 부르는 작은 묶음 단위로 주입하여 시스템을 훈련시킨다.\n",
    "매 학습 단계가 빠르고 비용이 적게 들어 시스템은 데이터가 도착하는 대로 즉시 학습할 수 있다.\n",
    "\n",
    "온라인 학습은 극도로 빠른 변화에 적응해야 하는 시스템(e.g. 주식 시장에서 새로운 패턴을 탐지하는 시스템)에 적합하다.\n",
    "컴퓨팅 자원이 제한된 경우에도 좋은 선택이다.\n",
    "예를 들면 모바일 디바이스에서 모델을 훈련할 경우이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "또한 온라인 학습 알고리즘을 사용하여 컴퓨터 한 대의 메인 메모리에 들어갈 수 없는 아주 큰 데이터셋에서 모델을 훈련할 수도 있다(이를 외부 메모리 학습 out-of-core learning이라고 한다). \n",
    "알고리즘이 데이터 일부를 읽어들이고 훈련 단계를 수행한다.\n",
    "그리고 전체 데이터가 모두 적용될 때까지 이 과정을 반복한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "온라인 학습 시스템에서 중요한 파라미터는 변화하는 데이터에 얼마나 빠르게 적응할 것인지이다.\n",
    "이를 학습률(learning rate)이라고 한다.\n",
    "학습률을 높게 하면 시스템이 데이터에 빠르게 적응하지만 예전 데이터를 금장 잊어버릴 것이다(최근에 나타난 스팸 종류만 걸러낼 수 있는 스팸 필터를 원할 리는 없다).\n",
    "반대로 학습률이 낮으면 시스템의 관성이 더 커져서 더 느리게 학습된다.\n",
    "하지만 새로운 데이터에 있는 잡음이나 대표성 없는 데이터 포인터에 덜 민감해진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "온라인 학습에서 가장 큰 문제점은 시스템에 나쁜 데이터가 주입되었을 때 시스템 성능이 감소한다는 점이다.\n",
    "데이터 품질과 학습률에 따라서 빠르게 감소할 수도 있다.\n",
    "운영 중인 시스템이라면 고객이 눈치챌지 모른다.\n",
    "버그로부터 나쁜 데이터가 올 수 있다.\n",
    "이런 위험을 줄이려면 시스템을 면밀히 모니터링하고 성능 감소가 감지되면 즉각 학슴을 중지시켜야 한다(가능하면 이전 운영 상태로 되돌린다).\n",
    "입력 데이터를 모니터링해서 비정상 데이터를 잡아낼 수도 있다.\n",
    "예컨대 이상치 탐지 알고리즘을 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1.4.3 사례 기반 학습과 모델 기반 학습**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어떻게 일반화(generalization)되는가에 따라 머신러닝 시스템을 분류할 수도 있다.\n",
    "대부분의 머신러닝 작업은 예측을 만드는 것이다.\n",
    "이 말은 주어진 훈련 데이터로 학습하고 이전에는 본적 없는 새로운 데이터에서 좋은 예측을 만들어야(일반화되어야) 한다는 뜻이다.\n",
    "훈련 데이터에서 높은 성능을 내는 것이 좋지만 그게 전부는 아니다.\n",
    "진짜 목표는 해로운 샘플에 잘 작동하는 모델이다.\n",
    "\n",
    "일반화를 위한 두 가지 접근법은 사례 기반 학습과 모델 기반 학습이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **사례 기반 학습**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가장 간단한 형태의 학습은 단순히 기억하는 것이다.\n",
    "스팸 필터를 이러한 방식으로 만들면 사용자가 스팸이라고 지정한 메일과 동일한 모든 메일을 스팸으로 분류한다.\n",
    "최악의 방법은 아니지만 최선도 아니다.\n",
    "\n",
    "스팸 메일과 동일한 메일을 스팸이라고 지정하는 대신 스팸 메일과 매우 유사한 메일을 구분되도록 스팸 필터를 프로그래밍할 수 있다.\n",
    "이렇게 하려면 두 메일 사이의 유사도(similarity)를 측정(measure)해야 한다.\n",
    "두 메일 사이의 매우 간단한 유사도 측정 방법은 공통으로 포함된 단어의 수를 세는 것이다.\n",
    "스팸 메일과 공통으로 가지고 있는 단어가 많으면 스팸으로 분류한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이를 사례 기반 학습(instance-based learning)이라고 한다.\n",
    "시스템이 훈련 샘플을 기억함으로써 학습한다.\n",
    "그리고 유사도를 측정을 사용해 새로운 데이터와 학습한 샘플(또는 학습한 샘플 중 일부)을 비교하는 식으로 일반화한다.\n",
    "예를 들어 새로운 샘플은 가장 비슷한 샘플 중 다수가 삼각형이므로 삼각형 클래스로 분류될 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **모델 기반 학습**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "샘플로부터 일반화시키는 다른 방법은 이 샘플들의 모델을 만들어 예측(prediction)에 사용하는 것이다.\n",
    "이를 모델 기반 학습(model-based learning)이라고 한다.\n",
    "\n",
    "모델을 사용하기 전에 모델 파라미터를 정의해야 한다.\n",
    "모델이 최상의 성능을 내도록 하는 값을 어떻게 알 수 있을까?\n",
    "이 질문에 대답하려면 측정 지표를 정해야 한다.\n",
    "모델이 얼마나 좋은지 측정하는 효용 함수(utility function)(또는 적합도 함수(fitness function))를 정의하거나 얼마나 나쁜지 측정하는 비용 함수(cost function)를 정의할 수 있다.\n",
    "선형 회귀에서는 보통 선형 모델의 예측과 훈련 데이터 사이의 거리를 재는 비용 함수를 사용한다.\n",
    "이 거리를 최소화하는 것이 목표이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기에서 선형 회귀(linear regression) 알고리즘이 등장한다.\n",
    "알고리즘에 훈련 데이터를 공급하면 데이터에 가장 잘 맞는 선형 모델의 파라미터를 찾는다.\n",
    "이를 모델을 훈련(training)시킨다고 말한다.\n",
    "\n",
    "이제 이 모델을 사용해 예측을 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 데이터를 다운로드하고 준비합니다.\n",
    "data_root = \"https://github.com/ageron/data/raw/main/\"\n",
    "lifesat = pd.read_csv(data_root + \"lifesat/lifesat.csv\")\n",
    "X = lifesat[[\"GDP per capita (USD)\"]].values\n",
    "y = lifesat[[\"Life satisfaction\"]].values\n",
    "\n",
    "# 데이터를 그래프로 나타낸다.\n",
    "lifesat.plot(kind='scatter',\n",
    "             grid=True,\n",
    "             x=\"GDP per captia (USD)\",\n",
    "             y=\"Life satisfaction\")\n",
    "plt.axis([23_500, 62_500, 4, 9])\n",
    "plt.show()\n",
    "\n",
    "# 선형 모델을 선택한다.\n",
    "model = LinearRegression()\n",
    "\n",
    "# 모델을 훈련한다.\n",
    "model.fit(X, y)\n",
    "\n",
    "# 키프로스에 대해 예측을 만든다.\n",
    "X_new = [[37_655.2]]    # 2020년 키프로스 1인당 GDP\n",
    "print(model.predict(X_new)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
